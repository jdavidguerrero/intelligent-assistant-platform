# ============================================================
# Intelligent Assistant Platform — Environment Variables
# ============================================================
# Copy to .env and fill in real values:
#   cp .env.example .env

# --- Required ---
OPENAI_API_KEY=sk-...

# --- Database ---
# Full SQLAlchemy connection URL.
#
# Local Docker (development):
DATABASE_URL=postgresql+psycopg://ia:ia@localhost:5432/ia
#
# Supabase (production) — use Direct connection, NOT the pooler:
# DATABASE_URL=postgresql+psycopg://postgres:[PASSWORD]@db.[PROJECT_REF].supabase.co:5432/postgres

# Docker Compose overrides (only needed for local dev)
POSTGRES_USER=ia
POSTGRES_PASSWORD=ia
POSTGRES_DB=ia
DB_PORT=5432

# --- Supabase (production) ---
# Get these from: Supabase Dashboard → Project Settings → API
# Needed for ESP32 / OpenDock device integration via PostgREST + Realtime.
# SUPABASE_URL=https://[PROJECT_REF].supabase.co
# SUPABASE_ANON_KEY=eyJ...
# SUPABASE_SERVICE_ROLE_KEY=eyJ...  (server-side only, never expose to devices)

# Connection pool tuning
DB_POOL_SIZE=5        # Persistent connections (increase for high concurrency)
DB_MAX_OVERFLOW=10    # Extra burst connections above pool_size

# --- LLM Generation ---
# Provider: "openai" (default) or "anthropic"
LLM_PROVIDER=openai

# --- Anthropic (for Tier 3 / claude-haiku realtime queries) ---
# ANTHROPIC_API_KEY=sk-ant-...

# --- Multi-Model Routing (opt-in) ---
# Set to "true" to enable 3-tier routing with cost tracking per request
# USE_ROUTING=false
# TIER_FAST_MODEL=gpt-4o-mini
# TIER_STANDARD_MODEL=gpt-4o
# TIER_LOCAL_MODEL=claude-haiku-4-20250514

# --- Redis (response cache + rate limiting) ---
# REDIS_URL=redis://localhost:6379/0
REDIS_PORT=6379

# --- MCP Server (hardware / AI agent integration) ---
# IAP_BASE_URL=http://localhost:8000

# --- OCR (optional — for scanned book ingestion) ---
# GOOGLE_VISION_API_KEY=your-vision-api-key
